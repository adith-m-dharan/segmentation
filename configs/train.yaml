# configs/train.yaml

# Model configuration
model:
  num_classes: 8
  backbone: "swin"             # Options: swin, resnet, etc.
  head: "mask2former"          # Options: mask2former, unet, etc.
  pretrained: true

# Training hyperparameters
training:
  epochs: 100
  batch_size: 64
  eval_freq: 5
  learning_rate: 1e-5
  optimizer: "adamw"
  scheduler: "step"            # Options: step, cosine, etc.
  step_size: 20
  gamma: 0.5
  weight_decay: 1e-3
  weight_ce: 1.0               # Weight for CrossEntropy
  weight_dice: 1.0             # Weight for Dice Loss
  warmup: true                # Enable warmup scheduling if desired
  warmup_epochs: 5             # Number of warmup epochs
  clipping: true              # Gradient clipping flag
  max_norm: 1.0

# Dataset and DataLoader settings
dataset:
  train_image_lmdb: "data/lmdb/train_images.lmdb"
  train_mask_lmdb: "data/lmdb/train_masks.lmdb"
  test_image_lmdb: "data/lmdb/test_images.lmdb"
  test_mask_lmdb: "data/lmdb/test_masks.lmdb"
  transform_size: [512, 512]   # Target image resize dimensions

# Paths for saving logs and results
paths:
  weights_path: "data/prepared/train/class_weights.pt"
  train_mask_dir: "data/prepared/train/masks"
  checkpoint_dir: "logs/checkpoints"
  output_checkpoint: "logs/checkpoints/latest.pth"
  output_inference_model: "logs/checkpoints/model.pth"
  results_dir: "logs/results"
  model_config: "configs/model.yaml"

# Hardware optimization and resource settings
hardware:
  device: "cuda"               # Options: "cuda" or "cpu"
  use_amp: true                # Automatic Mixed Precision
  num_workers: 4               # For DataLoader
  pin_memory: true             # Enable pin_memory for faster host-to-GPU transfer

# Logging configuration (using wandb, if enabled)
logging:
  use_wandb: true
  wandb_project: "segmentation_project"
  print_log_freq: 100
  image_log_freq: 1000
  wandb_log_freq: 10
